{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8230a447",
   "metadata": {},
   "source": [
    "# joblib module\n",
    "---\n",
    "\n",
    "# **1️⃣ What is `joblib`?**\n",
    "\n",
    "`joblib` is a **Python library for serializing (saving) and deserializing (loading) Python objects efficiently**.\n",
    "\n",
    "* Developed by the scikit-learn team, designed for **scientific Python workflows**.\n",
    "* Works exceptionally well with **large NumPy arrays, ML models, and pipelines**.\n",
    "* Main functions:\n",
    "\n",
    "  1. `joblib.dump(obj, filename)` → save Python object to disk\n",
    "  2. `joblib.load(filename)` → load Python object from disk\n",
    "\n",
    "Think of it as **pickle on steroids**, optimized for **numerical objects**.\n",
    "\n",
    "---\n",
    "\n",
    "# **2️⃣ Why `joblib` is Needed**\n",
    "\n",
    "### 2.1 Persistence of Models\n",
    "\n",
    "* Training ML models is **time-consuming**.\n",
    "* `joblib` allows you to **save a trained model** and reuse it without retraining.\n",
    "\n",
    "Example: RandomForestClassifier on Iris dataset might take seconds; large neural networks could take hours.\n",
    "\n",
    "### 2.2 Handling Large Arrays Efficiently\n",
    "\n",
    "* `pickle` can handle Python objects but is **slow for large NumPy arrays**.\n",
    "* `joblib` uses **efficient binary serialization**:\n",
    "\n",
    "  * Saves arrays in a **memory-mapped** form.\n",
    "  * Reads/writes directly to disk without loading everything in memory.\n",
    "\n",
    "### 2.3 Compression Support\n",
    "\n",
    "* Large models can take **hundreds of MBs**.\n",
    "* `joblib.dump()` supports compression:\n",
    "\n",
    "```python\n",
    "joblib.dump(model, 'model_compressed.pkl', compress=3)\n",
    "```\n",
    "\n",
    "* Compression levels: 0–9 (higher = smaller file, slower save/load)\n",
    "\n",
    "---\n",
    "\n",
    "# **3️⃣ Basic Workflow of joblib**\n",
    "\n",
    "### 3.1 Saving an Object\n",
    "\n",
    "```python\n",
    "import joblib\n",
    "\n",
    "data = {\"a\": [1,2,3], \"b\": [4,5,6]}\n",
    "joblib.dump(data, \"data.pkl\")\n",
    "```\n",
    "\n",
    "* Creates a **binary file** storing the object.\n",
    "* Efficient even for **nested dictionaries or large arrays**.\n",
    "\n",
    "### 3.2 Loading an Object\n",
    "\n",
    "```python\n",
    "loaded_data = joblib.load(\"data.pkl\")\n",
    "print(loaded_data)  # Output: {'a': [1, 2, 3], 'b': [4, 5, 6]}\n",
    "```\n",
    "\n",
    "* Exact object is **restored in memory**.\n",
    "\n",
    "---\n",
    "\n",
    "# **4️⃣ Saving & Loading ML Models (Scikit-learn Example)**\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "import joblib\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(model, \"iris_model.pkl\")\n",
    "\n",
    "# Load model\n",
    "loaded_model = joblib.load(\"iris_model.pkl\")\n",
    "\n",
    "# Prediction\n",
    "prediction = loaded_model.predict([[5.1, 3.5, 1.4, 0.2]])\n",
    "print(prediction)  # Output: [0]\n",
    "```\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "* `joblib` preserves the **entire trained object**, including:\n",
    "\n",
    "  * Model parameters\n",
    "  * Learned weights\n",
    "  * Preprocessing steps if using a pipeline\n",
    "\n",
    "---\n",
    "\n",
    "# **5️⃣ Advanced Usage**\n",
    "\n",
    "### 5.1 Memory-Mapped Arrays\n",
    "\n",
    "```python\n",
    "joblib.dump(array, \"array.pkl\", compress=0)\n",
    "loaded_array = joblib.load(\"array.pkl\", mmap_mode='r')\n",
    "```\n",
    "\n",
    "* `mmap_mode='r'` → allows **reading large arrays from disk** without loading into memory.\n",
    "* Useful for **large datasets or models**.\n",
    "\n",
    "### 5.2 Saving Multiple Objects\n",
    "\n",
    "```python\n",
    "joblib.dump([model1, model2], \"models.pkl\")\n",
    "models = joblib.load(\"models.pkl\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# **6️⃣ `joblib` vs `pickle`**\n",
    "\n",
    "| Feature                    | pickle | joblib                    |\n",
    "| -------------------------- | ------ | ------------------------- |\n",
    "| Performance (large arrays) | Slower | Faster, optimized         |\n",
    "| Compression                | Manual | Built-in (`compress=1-9`) |\n",
    "| ML Pipelines               | Works  | Works seamlessly          |\n",
    "| Memory-mapped support      | No     | Yes                       |\n",
    "\n",
    "* **Rule of thumb:** Use `pickle` for **small objects**, `joblib` for **ML models or large NumPy arrays**.\n",
    "\n",
    "---\n",
    "\n",
    "# **7️⃣ Using joblib in Flask **\n",
    "\n",
    "### 7.1 Scenario\n",
    "\n",
    "* You trained a **scikit-learn model offline**.\n",
    "* You want a **web interface** so users can input features and get predictions.\n",
    "\n",
    "### 7.2 Workflow\n",
    "\n",
    "1. **Train & Save Model**\n",
    "\n",
    "```python\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X, y)\n",
    "joblib.dump(model, \"iris_model.pkl\")\n",
    "```\n",
    "\n",
    "2. **Flask App**\n",
    "\n",
    "```python\n",
    "from flask import Flask, request, render_template\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load model at app startup\n",
    "model = joblib.load(\"iris_model.pkl\")\n",
    "\n",
    "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
    "def index():\n",
    "    if request.method == \"POST\":\n",
    "        # Convert form inputs to array\n",
    "        features = [float(request.form[f\"f{i}\"]) for i in range(1,5)]\n",
    "        features = np.array([features])\n",
    "        \n",
    "        # Prediction\n",
    "        pred = model.predict(features)[0]\n",
    "        target_names = [\"setosa\",\"versicolor\",\"virginica\"]\n",
    "        species = target_names[pred]\n",
    "\n",
    "        return render_template(\"result.html\", species=species)\n",
    "    return render_template(\"index.html\")\n",
    "```\n",
    "\n",
    "3. **Why joblib works well here**\n",
    "\n",
    "* **Fast model loading** → no retraining\n",
    "* **Supports large ML models** (Random Forest, Gradient Boosting, pipelines)\n",
    "* **Binary serialization** avoids text-based parsing issues\n",
    "\n",
    "---\n",
    "\n",
    "# **8️⃣ Best Practices**\n",
    "\n",
    "1. **Load once at app startup**\n",
    "\n",
    "   * Don’t call `joblib.load()` on every request → slows down response.\n",
    "\n",
    "2. **Save preprocessing pipeline with model**\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "pipeline.fit(X, y)\n",
    "joblib.dump(pipeline, \"pipeline_model.pkl\")\n",
    "```\n",
    "\n",
    "* Users can input raw values → pipeline handles preprocessing automatically.\n",
    "\n",
    "3. **Versioning**\n",
    "\n",
    "   * Keep track of model versions: `iris_model_v1.pkl`, `iris_model_v2.pkl`.\n",
    "\n",
    "4. **Compression for large models**\n",
    "\n",
    "```python\n",
    "joblib.dump(model, \"model_compressed.pkl\", compress=3)\n",
    "```\n",
    "\n",
    "5. **Security Note**\n",
    "\n",
    "* Only load **trusted joblib files**, as deserialization can execute arbitrary code.\n",
    "\n",
    "---\n",
    "\n",
    "# ✅ Key Takeaways\n",
    "\n",
    "* `joblib` is **essential for deploying ML models in production**.\n",
    "* Optimized for **speed and memory efficiency**.\n",
    "* Works seamlessly with **Flask** for **interactive web-based predictions**.\n",
    "* Supports **pipelines, large arrays, compression, memory-mapped arrays**.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdbceb9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
